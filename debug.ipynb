{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "x shape: torch.Size([1, 512, 1])\n",
      "y shape: torch.Size([1, 512, 1])\n",
      "input_geom shape: torch.Size([1, 512, 3])\n",
      "latent_queries shape: torch.Size([1, 8, 8, 8, 3])\n",
      "output_queries shape: torch.Size([512, 3])\n",
      "latent_embed.shape=torch.Size([1, 64, 8, 8, 8])\n",
      "latent_embed.shape=torch.Size([1, 512, 64]) after permute\n",
      "---going into output GNO---\n",
      "out.shape=torch.Size([1, 512, 64])\n",
      "Loss: 0.030690349638462067\n",
      "Number of unused parameters: 0\n",
      "Single batch forward and backward pass completed.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from neuralop.models import GINO\n",
    "from tensorly import tenalg\n",
    "from cfd_dataset import CFDDataset, CFDDatasetWrapper\n",
    "\n",
    "tenalg.set_backend(\"einsum\")\n",
    "\n",
    "def test_gino_single_batch(model, x, y, input_geom, latent_queries, output_queries, device):\n",
    "    model.to(device)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    # Get a single batch from the train_loader\n",
    "    # try:\n",
    "    #     x, y, output_queries = next(iter(train_loader))\n",
    "    # except StopIteration:\n",
    "    #     print(\"Error: The train_loader is empty. Make sure your dataset is not empty.\")\n",
    "    #     return\n",
    "\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    output_queries = output_queries.to(device)\n",
    "    \n",
    "    x.requires_grad_(True)  # Enable gradient computation for x\n",
    "    \n",
    "    print(f\"x shape: {x.shape}\")\n",
    "    print(f\"y shape: {y.shape}\")\n",
    "    print(f\"input_geom shape: {input_geom.shape}\")\n",
    "    print(f\"latent_queries shape: {latent_queries.shape}\")\n",
    "    print(f\"output_queries shape: {output_queries.shape}\")\n",
    "\n",
    "    ada_in = torch.randn(1, device=device)  # Random ada_in for the batch\n",
    "    \n",
    "    # Forward pass\n",
    "    output = model(x, input_geom, latent_queries, output_queries, ada_in=ada_in)\n",
    "    \n",
    "    # Compute loss\n",
    "    loss = criterion(output, y)\n",
    "    \n",
    "    print(f\"Loss: {loss.item()}\")\n",
    "\n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "\n",
    "    # Check if all parameters have gradients\n",
    "    n_unused_params = sum(1 for param in model.parameters() if param.grad is None)\n",
    "    print(f\"Number of unused parameters: {n_unused_params}\")\n",
    "\n",
    "    # Check if output is finite\n",
    "    if not output.isfinite().all():\n",
    "        print(\"Warning: Output contains non-finite values!\")\n",
    "\n",
    "    if x.shape[0] > 1:\n",
    "        # Check if x[1:] accumulates no grad\n",
    "        if x.grad[1:].nonzero().any():\n",
    "            print(\"Warning: Unexpected gradients in x[1:]\")\n",
    "\n",
    "    print(\"Single batch forward and backward pass completed.\")\n",
    "\n",
    "def main():\n",
    "    # Hyperparameters\n",
    "    batch_size = 2\n",
    "    num_train_samples = 250  # Adjust based on your dataset\n",
    "\n",
    "    # Create dataset\n",
    "    train_dataset = CFDDataset('data/', num_train_samples)\n",
    "\n",
    "    # Wrap dataset to only return x, y, and output_queries\n",
    "    train_dataset_wrapped = CFDDatasetWrapper(train_dataset)\n",
    "\n",
    "    # Create data loader\n",
    "    train_loader = DataLoader(train_dataset_wrapped, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "\n",
    "    # Get input_geom and latent_queries from the first item of the dataset\n",
    "    x, y, input_geom, latent_queries, output_queries = train_dataset[0]\n",
    "\n",
    "    # Initialize GINO model\n",
    "    model = GINO(\n",
    "        in_channels=1,  # 1 for pressure\n",
    "        out_channels=1,  # 1 for smoke concentration\n",
    "        gno_coord_dim=3,\n",
    "        gno_radius=0.3,\n",
    "        projection_channels=16,\n",
    "        in_gno_mlp_hidden_layers=[16, 16],\n",
    "        out_gno_mlp_hidden_layers=[16, 16],\n",
    "        in_gno_transform_type=\"nonlinear\",\n",
    "        out_gno_transform_type=\"nonlinear\",\n",
    "        fno_n_modes=(16, 16, 16),\n",
    "        fno_hidden_channels=64,\n",
    "        fno_lifting_channels=16,\n",
    "        fno_projection_channels=16,\n",
    "        fno_norm=\"ada_in\",\n",
    "    )\n",
    "\n",
    "    # Set device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # Move input_geom and latent_queries to the device\n",
    "    input_geom = input_geom.to(device)\n",
    "    latent_queries = latent_queries.to(device)\n",
    "        \n",
    "    # Run the single batch test\n",
    "    test_gino_single_batch(model, x, y, input_geom, latent_queries, output_queries, device)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "physicsml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
